pipeline {
  agent any
  environment {
    DOTNET_CLI_TELEMETRY_OPTOUT = '1'

    // === Service-specific ===
    PROJECT_DIR = 'summerProject/Services/Catalog/Catalog.API'
    CSPROJ      = 'summerProject/Services/Catalog/Catalog.API/Catalog.API.csproj'

    DOCKERHUB   = credentials('dockerhub-creds')
    IMAGE_REPO  = 'duythong2/catalog-api'
    IMAGE_TAG   = "${env.BUILD_NUMBER}"

    SONAR_TOKEN       = credentials('sonartoken')
    SONAR_PROJECT_KEY = 'catalog-api'

    // Optional toggles
    ENABLE_SONAR_BRANCH   = '0'
    DOCKER_LOCK_RESOURCE  = 'docker-daemon'
  }
  options { timestamps(); disableConcurrentBuilds() }

  stages {
    stage('Checkout') { steps { checkout scm } }

    stage('Detect relevant changes') {
      steps {
        script {
          def isFirst = (sh(returnStatus: true, script: 'git rev-parse HEAD~1 >/dev/null 2>&1') != 0)
          def diff = sh(returnStdout: true, script: '''
            set -e
            git fetch --no-tags origin || true
            if [ -n "$CHANGE_TARGET" ]; then
              git diff --name-only "origin/$CHANGE_TARGET"...HEAD
            else
              if git rev-parse HEAD~1 >/dev/null 2>&1; then
                git diff --name-only HEAD~1..HEAD
              else
                echo ""
              fi
            fi
          ''').trim().split("\\r?\\n").findAll { it?.trim() }

          // Catalog service + BuildingBlocks
          def pattern  = ~/^(summerProject\/Services\/Catalog\/|summerProject\/BuildingBlocks\/).*/
          def relevant = isFirst || diff.any { it ==~ pattern }

          writeFile file: '.run_pipeline', text: (relevant ? '1' : '0')

          if (relevant) {
            def touched = diff.findAll { it ==~ pattern }
            echo "Relevant changes detected (or first build). Running heavy stages."
            if (touched) { echo "Touched files:\n" + touched.join('\n') }
          } else {
            echo "No relevant changes for Catalog/BuildingBlocks. Heavy stages will be skipped (build stays GREEN)."
          }
        }
      }
    }

    stage('Start Analysis') {
      when { expression { fileExists('.run_pipeline') && readFile('.run_pipeline').trim() == '1' } }
      steps {
        withSonarQubeEnv('sonarServer') {
          sh '''
            set -e
            if [ ! -f .config/dotnet-tools.json ]; then
              dotnet new tool-manifest
              dotnet tool install dotnet-sonarscanner --version 10.3.0
            else
              dotnet tool restore
            fi
          '''
          script {
            def args = [
              'dotnet tool run dotnet-sonarscanner begin',
              "/k:${env.SONAR_PROJECT_KEY}",
              "/d:sonar.login=${env.SONAR_TOKEN}",
              "/d:sonar.host.url=${env.SONAR_HOST_URL}"
            ]
            if ((env.ENABLE_SONAR_BRANCH ?: '0') == '1' &&
                env.BRANCH_NAME && !(env.BRANCH_NAME in ['main','master'])) {
              args << "/d:sonar.branch.name=${env.BRANCH_NAME}"
            }
            sh args.join(' ')
          }
        }
      }
    }

    stage('Restore') {
      when { expression { fileExists('.run_pipeline') && readFile('.run_pipeline').trim() == '1' } }
      steps { sh 'dotnet restore "$CSPROJ"' }
    }

    stage('Build') {
      when { expression { fileExists('.run_pipeline') && readFile('.run_pipeline').trim() == '1' } }
      steps { sh 'dotnet build "$CSPROJ" -c Release --no-restore' }
    }

    stage('Test') {
      when { expression { fileExists('.run_pipeline') && readFile('.run_pipeline').trim() == '1' } }
      steps { sh 'dotnet test "$CSPROJ" -c Release --no-build --logger "trx;LogFileName=test.trx"' }
    }

    stage('Publish') {
      when { expression { fileExists('.run_pipeline') && readFile('.run_pipeline').trim() == '1' } }
      steps { sh 'dotnet publish "$CSPROJ" -c Release --no-build -o "$PROJECT_DIR/publish"' }
    }

    stage('Finish Analysis') {
      when { expression { fileExists('.run_pipeline') && readFile('.run_pipeline').trim() == '1' } }
      steps {
        withSonarQubeEnv('sonarServer') {
          sh 'dotnet tool run dotnet-sonarscanner end /d:sonar.login="$SONAR_TOKEN"'
        }
      }
    }

    stage('Quality Gate') {
      when { expression { fileExists('.run_pipeline') && readFile('.run_pipeline').trim() == '1' } }
      steps {
        timeout(time: 10, unit: 'MINUTES') {
          script {
            def qg = waitForQualityGate()
            if (qg.status != 'OK') { error "Quality Gate failed: ${qg.status}" }
          }
        }
      }
    }

    stage('Docker Build & Push') {
      when { expression { fileExists('.run_pipeline') && readFile('.run_pipeline').trim() == '1' } }
      steps {
        sh '''
          echo "$DOCKERHUB_PSW" | docker login -u "$DOCKERHUB_USR" --password-stdin
          docker build -t "$IMAGE_REPO":"$IMAGE_TAG" -f "$PROJECT_DIR/Dockerfile" summerProject
          docker push  "$IMAGE_REPO":"$IMAGE_TAG"
          docker tag   "$IMAGE_REPO":"$IMAGE_TAG" "$IMAGE_REPO":latest
          docker push  "$IMAGE_REPO":latest
        '''
      }
    }
  }

  post {
      success {
        sh '''
          set -e
          KEEP1="$IMAGE_REPO:$IMAGE_TAG"
          KEEP2="$IMAGE_REPO:latest"

          # Collect images of this repo except current & latest
          TO_DELETE=$(docker images --format '{{.Repository}}:{{.Tag}} {{.ID}}' | \
            awk -v repo="$IMAGE_REPO" -v k1="$KEEP1" -v k2="$KEEP2" '
              $1 ~ ("^"repo":") && $1 != k1 && $1 != k2 {print $2}
            ' | sort -u)

          if [ -n "$TO_DELETE" ]; then
            echo "Removing old images for $IMAGE_REPO (excluding $KEEP1 and $KEEP2):"
            echo "$TO_DELETE" | xargs -r -n1 docker image rm -f || true
          else
            echo "No old images to remove for $IMAGE_REPO"
          fi
        '''
      }
      always {
        sh 'rm -f .run_pipeline || true'
        junit allowEmptyResults: true, testResults: '**/TestResults/**/*.trx'
      }
   }
}
